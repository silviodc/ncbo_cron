#!/usr/bin/env ruby

$0 = "ncbo_cron"

# Exit cleanly from an early interrupt
Signal.trap("INT") { exit 1 }

# Setup the bundled gems in our environment
require 'bundler/setup'
# redis store for looking up queued jobs
require 'redis'

# Used for getting jobs from the queue and processing them
require_relative '../lib/ncbo_cron'
config_exists = File.exist?(File.expand_path('../../config/config.rb', __FILE__))
abort("Please create a config/config.rb file using the config/config.rb.sample as a template") unless config_exists
require_relative '../config/config'

#################
## IMPORTANT
#################
# We shut off security for LinkedData when we run the cron bin because otherwise ontologies can't get updated
# This has to happen after the config file has been loaded, to make sure it won't get overwritten
LinkedData.settings.enable_security = false

require 'optparse'
options = NcboCron.settings.to_h
opt_parser = OptionParser.new do |opts|
  # Set a banner, displayed at the top of the help screen.
  opts.banner = "Usage: ncbo_cron [options]"

  # Options from Dante gem, see
  # https://github.com/nesquena/dante/blob/master/lib/dante/runner.rb#L168-L214
  opts.on("-d", "--daemon", "Daemonize mode") do |v|
    options[:daemonize] = true
  end
  opts.on("-k", "--kill [PORT]", String, "Kill specified running daemons - leave blank to kill all.") do |v|
    options[:kill] = v
  end
  opts.on("-p", "--port PORT", Integer, "Specify port", "(default: #{options[:port]})") do |v|
    options[:port] = v
  end
  opts.on("-P", "--pid FILE", String, "save PID in FILE when using -d option.", "(default: #{options[:pid_path]})") do |v|
    options[:pid_path] = File.expand_path(v)
  end
  opts.on("-l", "--log FILE", String, "Logfile for output", "(default: #{options[:log_path]})") do |v|
    options[:log_path] = v
  end
  opts.on("-u", "--user USER", String, "User to run as") do |user|
    options[:user] = user
  end
  opts.on("-G", "--group GROUP", String, "Group to run as") do |group|
    options[:group] = group
  end

  # NCBO Cron options (may override options above, see validation below)
  opts.on("--console", "REPL for working with scheduler") do |v|
    options[:console] = true
  end
  opts.on("-v", "--view-queue", "view queued jobs") do |v|
    options[:view_queue] = true
  end
  opts.on("-a", "--add-submission ID", String, "submission id to add to the queue") do |v|
    options[:queue_submission] = v
  end
  opts.on("-h", "--redis-host HOST", String, "redis host (for shared locking)", "(default: #{options[:redis_host]})") do |host|
    options[:redis_host] = host
  end
  opts.on("-p", "--redis-port PORT", Integer, "redis port (for shared locking)", "(default: #{options[:redis_port]})") do |port|
    options[:redis_port] = port
  end
  opts.on("-l", "--log-level LEVEL", String, "set the log level (debug, info, error)", "(default: #{options[:log_level]})") do |c|
    options[:log_level] = c.to_sym
  end
  opts.on("-m", "--minutes MIN", Integer, "minutes between process queue checks (override seconds)", "(default: #{options[:minutes_between]})") do |m|
    options[:minutes_between] = m
  end
  opts.on("-s", "--seconds SEC", Integer, "seconds between process queue checks") do |s|
    options[:seconds_between] = s
  end
  opts.on("--disable-processing", "disable ontology processing") do |v|
    options[:enable_processing] = false
  end
  opts.on("--disable-pull", "disable ontology pull") do |v|
    options[:enable_pull] = false
  end
  opts.on("--disable-flush", "disable flush archive class graphs") do |v|
    options[:enable_flush] = false
  end
  opts.on("--disable-warmq", "disable query warmer") do |v|
    options[:enable_warmq] = false
  end
  opts.on("--disable-mapping-counts", "disable mapping counts creation") do |v|
    options[:enable_mapping_counts] = false
  end
  opts.on("--enable-umls", "enable UMLS auto-pull") do |v|
    options[:enable_pull_umls] = true
  end
  opts.on("--disable-ontology-analytics", "disable ontology analytics refresh", "(default: #{options[:enable_ontology_analytics]})") do |v|
    options[:enable_ontology_analytics] = false
  end
  opts.on("--disable-ontologies-report", "disable ontologies report generation", "(default: #{options[:enable_ontologies_report]})") do |v|
    options[:enable_ontologies_report] = false
  end
  opts.on("--pull-umls-url URL", "set UMLS pull location") do |v|
    options[:pull_umls_url] = v
  end
  opts.on("-c", "--pull-cron SCHED", String, "cron schedule for ontology pull", "(default: #{options[:pull_schedule]})") do |c|
    options[:pull_schedule] = c
  end
  opts.on("-f", "--flush-old-graphs SCHED", String, "cron schedule to delete class graphs of archive submissions", "(default: #{options[:cron_flush]})") do |c|
    options[:cron_flush] = c
  end
  opts.on("-w", "--warm-long-queries SCHED", String, "cron schedule to warmup long time running queries", "(default: #{options[:cron_warmq]})") do |c|
    options[:cron_warmq] = c
  end  
  opts.on("-m", "--create-mapping-counts SCHED", String, "cron schedule to create mapping counts", "(default: #{options[:cron_mapping_counts]})") do |c|
    options[:cron_mapping_counts] = c
  end
  opts.on("--ontology-analytics SCHED", String, "cron schedule to run ontology analytics refresh", "(default: #{options[:cron_ontology_analytics]})") do |c|
    options[:cron_ontology_analytics] = c
  end
  opts.on("--ontologies-report SCHED", String, "cron schedule to run ontologies report generation", "(default: #{options[:cron_ontologies_report]})") do |c|
    options[:cron_ontologies_report] = c
  end

  # Display the help screen, all programs are assumed to have this option.
  opts.on_tail('--help', 'Display this screen') do
    puts opts
    exit
  end
end
# Parse the command-line. The 'parse' method simply parses ARGV, while the 'parse!' method parses ARGV and removes
# any options found there, as well as any parameters for the options.
opt_parser.parse!

# Verify options: daemon mode takes a back seat to other options.
if options[:view_queue] || options[:queue_submission] || options[:console] || options.include?(:kill)
  options[:daemonize] = false
  # The Dante runner will automatically redirect logs on runner.execute, if this option is set.
  options.delete(:log_path) # remove this here for more control over logging
end
if options[:daemonize] || options.include?(:kill)
  options[:console] = false
  options[:view_queue] = false
  options[:queue_submission] = false
  puts "Log file: #{options[:log_path]}" if options[:daemonize]
end

# Update the NcboCron.settings with CLI options
options.each_pair {|k,v| NcboCron.settings[k] = v}


# Configure the process controller
require 'dante'
runner = Dante::Runner.new('ncbo_cron', options)
runner.description = "This will run a scheduled job for NCBO-related processing"
runner.execute do |opts|

  redis = Redis.new(host: opts[:redis_host], port: opts[:redis_port])
  puts "Running ncbo_cron with redis: #{redis.inspect}"

  # If we're viewing queued entries, show them and quit
  if opts[:view_queue]
    parser = NcboCron::Models::OntologySubmissionParser.new
    queued_items = parser.queued_items(redis).map {|a| {ontology: a[:key], actions: a[:actions]}}
    puts "\n"
    queued_items.empty? ? puts("Nothing queued") : pp(queued_items)
    exit
  end

  # Queue a provided submission, then exit
  if opts[:queue_submission]
    puts "\n\nQueueing submission: #{opts[:queue_submission]}"
    sub = LinkedData::Models::OntologySubmission.find(RDF::URI.new(opts[:queue_submission])).first
    abort("Error: Submission not found") unless sub
    parser = NcboCron::Models::OntologySubmissionParser.new
    parser.queue_submission(sub)
    exit
  end

  if opts[:console]
    require 'pry'; binding.pry(quiet: true)
    exit
  end

  # Redirect stdout, stderr
  # The log opts are not set until now, because the stdout/stderr should not be
  # redirected for the view_queue, queue_submission, or console; the runner will
  # automatically redirect to logs on runner.execute, if the opts are set.
  require 'logger'
  log_file = File.new(options[:log_path], "a")
  log_path = File.dirname(File.absolute_path(log_file))
  log_filename_noExt = File.basename(log_file, ".*")
  logger = Logger.new(log_file)
  $consoleerr = $stderr
  $consoleout = $stdout
  $stderr = log_file
  $stdout = log_file
  log_levels = {
    fatal: Logger::FATAL,
    error: Logger::ERROR,
    warn:  Logger::WARN,
    info:  Logger::INFO,
    debug: Logger::DEBUG
  }
  logger.level = log_levels[options[:log_level]] || Logger::INFO
  options['logger'] = logger

  puts "Running ncbo_cron with options:"
  pp options

  if options[:enable_processing]
    parsing_thread = Thread.new do
      logger.debug "Setting up process queue check job"; logger.flush
      parse_options = options.dup
      parse_options.delete(:cron_schedule)
      parse_options[:job_name] = "ncbo_cron_parsing"
      NcboCron::Scheduler.scheduled_locking_job(parse_options) do
        logger.info "Starting ontology process queue check"; logger.flush
        parser = NcboCron::Models::OntologySubmissionParser.new
        parser.process_queue_submissions()
        logger.info "Finished ontology process queue check"; logger.flush
      end
    end
  end

  if options[:enable_pull]
    pull_thread = Thread.new do
      logger.debug "Setting up pull cron job"; logger.flush
      pull_options = options.dup
      pull_options.delete(:minutes_between)
      pull_options.delete(:seconds_between)
      pull_options[:job_name] = "ncbo_cron_pull_thread"
      pull_options[:scheduler_type] = :cron
      pull_options[:cron_schedule] = pull_options[:pull_schedule]
      pull_log_path = File.join(log_path, "#{log_filename_noExt}-pull.log")
      pull_logger = Logger.new(pull_log_path)
      NcboCron::Scheduler.scheduled_locking_job(pull_options) do
        logger.info "Starting ncbo pull"; logger.flush
        logger.info "Logging pull details to #{pull_log_path}"; logger.flush
        puller = NcboCron::Models::OntologyPull.new
        pulled_onts = puller.do_remote_ontology_pull(logger: pull_logger,
         enable_pull_umls: options[:enable_pull_umls])
        logger.info "Finished ncbo pull"; logger.flush
        logger.info "Pull summary:\n#{pulled_onts.map {|o| o.id.to_s}}"
      end
    end
  end

  if options[:enable_flush]
    flush_thread = Thread.new do
      flush_options = options.dup
      flush_options.delete(:minutes_between)
      flush_options.delete(:seconds_between)
      flush_options[:job_name] = "ncbo_cron_flush_thread"
      flush_options[:scheduler_type] = :cron
      flush_options[:cron_schedule] = flush_options[:cron_flush]
      logger.debug "Setting up the flush cron job with options #{flush_options[:cron_flush]}"; logger.flush
      flush_log_path = File.join(log_path, "#{log_filename_noExt}-flush.log")
      flush_logger = Logger.new(flush_log_path)
      NcboCron::Scheduler.scheduled_locking_job(flush_options) do
        logger.info "Starting ncbo flush"; logger.flush
        logger.info "Logging flush details to #{flush_log_path}"; logger.flush
        t0 = Time.now
        parser = NcboCron::Models::OntologySubmissionParser.new
        flush_onts = parser.process_flush_classes(flush_logger, flush_options[:remove_zombie_graphs])
        logger.info "Flushed #{flush_onts.length} submissions in #{Time.now - t0} sec."; logger.flush
        logger.info "Finished flush"; logger.flush
      end
    end
  end

  if options[:enable_warmq]
    warmq_thread = Thread.new do
      warmq_options = options.dup
      warmq_options.delete(:minutes_between)
      warmq_options.delete(:seconds_between)
      warmq_options[:job_name] = "ncbo_cron_warmq_thread"
      warmq_options[:scheduler_type] = :cron
      warmq_options[:cron_schedule] = warmq_options[:cron_warmq]
      logger.debug "Setting up warm up queries #{warmq_options[:cron_warmq]}"; logger.flush
      warmq_log_path = File.join(log_path, "#{log_filename_noExt}-warmq.log")
      warmq_logger = Logger.new(warmq_log_path)
      NcboCron::Scheduler.scheduled_locking_job(warmq_options) do
        logger.info "Starting ncbo warmq"; logger.flush
        logger.info "Logging warmq details to #{warmq_log_path}"; logger.flush
        t0 = Time.now
        NcboCron::Models::QueryWarmer.new(warmq_logger).run
        logger.info "Warm queries job run in #{Time.now - t0} sec."; logger.flush
        logger.info "Finished warmq"; logger.flush
      end
    end
  end

  if options[:enable_mapping_counts]
    mapping_counts_thread = Thread.new do
      mapping_counts_options = options.dup
      mapping_counts_options[:job_name] = "ncbo_cron_mapping_counts_thread"
      mapping_counts_options[:scheduler_type] = :cron
      mapping_counts_options[:cron_schedule] = mapping_counts_options[:cron_mapping_counts]
      logger.debug "Setting up the mapping counts creation cron job with options #{mapping_counts_options[:cron_mapping_counts]}"; logger.flush
      mapping_counts_log_path = File.join(log_path, "#{log_filename_noExt}-mapping-counts.log")
      mapping_counts_logger = Logger.new(mapping_counts_log_path)
      NcboCron::Scheduler.scheduled_locking_job(mapping_counts_options) do
        logger.info "Starting mapping counts creation"; logger.flush
        logger.info "Logging mapping counts creation details to #{mapping_counts_log_path}"; logger.flush
        t0 = Time.now
        NcboCron::Models::MappingCounts.new(mapping_counts_logger).run
        logger.info "Mapping counts creation job completed in #{Time.now - t0} sec."; logger.flush
        logger.info "Finished mapping counts creation"; logger.flush
      end
    end
  end

  if options[:enable_ontology_analytics]
    analytics_thread = Thread.new do
      ontology_analytics_options = options.dup
      ontology_analytics_options[:job_name] = "ncbo_cron_ontology_analytics"
      ontology_analytics_options[:scheduler_type] = :cron
      ontology_analytics_options[:cron_schedule] = ontology_analytics_options[:cron_ontology_analytics]
      logger.info "Setting up ontology analytics refresh job with #{ontology_analytics_options[:cron_ontology_analytics]}"; logger.flush
      ontology_analytics_log_path = File.join(log_path, "#{log_filename_noExt}-ontology-analytics.log")
      ontology_analytics_logger = Logger.new(ontology_analytics_log_path)
      NcboCron::Scheduler.scheduled_locking_job(ontology_analytics_options) do
        logger.info "Starting ontology analytics refresh"; logger.flush
        logger.info "Logging ontology analytics refresh details to #{ontology_analytics_log_path}"; logger.flush
        t0 = Time.now
        NcboCron::Models::OntologyAnalytics.new(ontology_analytics_logger).run
        logger.info "Ontology analytics refresh job completed in #{Time.now - t0} sec."; logger.flush
        logger.info "Finished ontology analytics refresh"; logger.flush
      end
    end
  end

  if options[:enable_ontologies_report]
    ontologies_report_thread = Thread.new do
      ontologies_report_options = options.dup
      ontologies_report_options[:job_name] = "ncbo_cron_ontologies_report"
      ontologies_report_options[:scheduler_type] = :cron
      ontologies_report_options[:cron_schedule] = ontologies_report_options[:cron_ontologies_report]
      logger.info "Setting up ontologies report generation job with #{ontologies_report_options[:cron_ontologies_report]}"
      logger.info "Writing ontologies report into #{ontologies_report_options[:ontology_report_path]}"; logger.flush
      ontologies_report_log_path = File.join(log_path, "#{log_filename_noExt}-ontologies-report.log")
      ontologies_report_logger = Logger.new(ontologies_report_log_path)
      NcboCron::Scheduler.scheduled_locking_job(ontologies_report_options) do
        logger.info "Starting ontologies report generation"; logger.flush
        logger.info "Logging ontologies report generation details to #{ontologies_report_log_path}"; logger.flush
        t0 = Time.now
        NcboCron::Models::OntologiesReport.new(ontologies_report_logger, ontologies_report_options[:ontology_report_path]).run
        logger.info "Ontologies report generation job completed in #{Time.now - t0} sec."; logger.flush
        logger.info "Finished ontologies report generation"; logger.flush
      end
    end
  end

  # Print running child processes
  require 'sys/proctable'
  at_exit do
    procs = Sys::ProcTable.ps.select {|pe| pe.ppid == $$ && !pe.state.eql?("zombie") }
    unless procs.empty?
      $consoleout.puts "The following child processes may still be running\npid\tname"
      procs.each {|pe| $consoleout.puts pe.pid.to_s + "\t" + pe.cmdline.split(" ").first}
    end
  end

  # Need to join here to avoid dropping out of the process
  parsing_thread.join if parsing_thread
  pull_thread.join if pull_thread
  flush_thread.join if flush_thread
  warmq_thread.join if warmq_thread
  analytics_thread.join if analytics_thread
  ontologies_report_thread.join if ontologies_report_thread
  mapping_counts_thread.join if mapping_counts_thread
end
